{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Lesson 7 - Implementing RNNs with fast.ai",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/marianqian/Intro-to-ML-and-DL-Using-fast.ai/blob/master/notebooks/Lesson_7_Implementing_RNNs_with_fast_ai.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F7XZ2Tytq0dy",
        "colab_type": "text"
      },
      "source": [
        "Welcome to the AI Academy! This is the seventh and last lesson, focused on learning how to use the fast.ai library to build recurrent neural networks (RNNs). We used [fastai](https://www.fast.ai/) in the Lesson 4, 5, and 6 Google Colab notebooks, so please make sure you understand how the data was loaded and processed and how normal, or fully connected, neural networks because we will be building upon that previous knowledge in this notebook.\n",
        "\n",
        "You can learn more about fastai [here](https://docs.fast.ai/); the library is split between four different parts, which are vision, text, tabular, and collab models. fastai focuses on neural networks, and for the rest of the course we will be exploring how to use this library. \n",
        "\n",
        "The creater of fastai, Jeremy Howard, also taught a course explaining how to use the library and introduces deep learning to those who have no experience with it before. We highly recommend you to look at his videos linked [here](https://course.fast.ai/videos/?lesson=1) when you have the time. \n",
        "\n",
        "NOTE: Educational use and distribution is permitted, but credit and attribution to AIM Academy is required. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uKDCNNbsq1vs",
        "colab_type": "text"
      },
      "source": [
        "#Learning Objectives: \n",
        "* Understand how to use recurrent neural networks (RNNs)\n",
        "* Use the `fastai.text` section of the `fastai` library.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wGMS4d6b3P0I",
        "colab_type": "text"
      },
      "source": [
        "In this notebook, we will be basing off our code from the [fastai Lesson 7 Human numbers notebook](https://github.com/fastai/course-v3/blob/master/nbs/dl1/lesson7-human-numbers.ipynb). We will use the the `fastai.text` section of the `fastai` library, and we will train our recurrent neural network to count numbers. Given three words, the model will predict what word would come after. The training examples we give to our model are spelled out sequences of words from 1 to 9,999 (**\"one , two , three , four , five ... eight thousand , eight thousand one ... nine thousand nine hundred ninety nine\"**).\n",
        "\n",
        "For example, if we give our model \"ten , eleven , twelve\", we want our model to predict \"thirteen\" as a result. \n",
        "\n",
        "\n",
        "```\n",
        "#CODE BELOW IS FULLY CREDITED TO FASTAI (fast.ai)\n",
        "#USED ONLY FOR EDUCATIONAL PURPOSES UNDER FAIR USE\n",
        "```\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3515wois3SIq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from fastai.text import *"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WNCVFsE5xgqq",
        "colab_type": "text"
      },
      "source": [
        "Here, we use `URLs.HUMAN_NUMBERS` to access the data we want to use for the RNN by passing it through the `untar_data`method. After calling `path.ls()`, we can see that the path to the images are from the `human_numbers` folder, and two files are located inside, `train.txt` and `valid.txt`. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VukpJKtn3aDf",
        "colab_type": "code",
        "outputId": "f5bd54ce-76b5-46a1-842c-381c403e0019",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        }
      },
      "source": [
        "path = untar_data(URLs.HUMAN_NUMBERS)\n",
        "path.ls()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading http://files.fast.ai/data/examples/human_numbers\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[PosixPath('/root/.fastai/data/human_numbers/train.txt'),\n",
              " PosixPath('/root/.fastai/data/human_numbers/valid.txt')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dp4encIyylLH",
        "colab_type": "text"
      },
      "source": [
        "We define the method `readnums` to read in the words of the `.txt` file into a list. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z5glPfy-3aHy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def readnums(d): return [', '.join(o.strip() for o in open(path/d).readlines())]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bd7Kx9_CuMyf",
        "colab_type": "code",
        "outputId": "88a6dbab-c1c2-4cfe-e53c-bb9a987f25b9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "train_txt = readnums('train.txt')\n",
        "train_txt[0][:80]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'one, two, three, four, five, six, seven, eight, nine, ten, eleven, twelve, thirt'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GJhMS3EJuQce",
        "colab_type": "code",
        "outputId": "076d281c-805e-4f65-f94c-267c6e19f7d9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "valid_txt = readnums('valid.txt')\n",
        "valid_txt[0][-80:]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' nine thousand nine hundred ninety eight, nine thousand nine hundred ninety nine'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2cSfdt7UucX5",
        "colab_type": "text"
      },
      "source": [
        "The lists (`train_txt` and `valid_txt`) each contain ONE STRING with all the words from the '.txt' files, and we index into the string by calling `[:80]` or `[-80:]` which gives us the first 80 characters from `train_txt` and the last 80 characters from `valid_txt` printed above.\n",
        "\n",
        "The training dataset includes numbers from 1 to 8,000, and the validation set indcludes the rest of the numbers, 8,001 to 9,999. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zvccGbK_y5DU",
        "colab_type": "text"
      },
      "source": [
        "Using the `train_txt` and `valid_txt`lists, we can use the `TextList` class, a subclass of the `ItemList` class, to store the words. \n",
        "\n",
        "A `DataBunch` is created, where we pass in the `valid` and `train` TextLists. The DataBunch can be directly passed into the model we create later. \n",
        "\n",
        "Note how we set our batch size `bs` to be 64. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GEbg46oh3aLH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train = TextList(train_txt, path=path)\n",
        "valid = TextList(valid_txt, path=path)\n",
        "\n",
        "data = ItemLists(path=path, train=train, valid=valid).label_for_lm().databunch(bs=64)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wv33iqOYCYdy",
        "colab_type": "text"
      },
      "source": [
        "The validation set contains a total number of about 13,000 chracters. The backpropgation through time `bptt` is 70, which is essentially the number of tokens or characters we pass to the model for every batch. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QBj-Mw6Mxfv2",
        "colab_type": "code",
        "outputId": "b3fa5724-ca78-4a8e-9996-8fa3aa4bfad2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "len(data.valid_ds[0][0].data)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "13017"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ofYtiiwL3aOJ",
        "colab_type": "code",
        "outputId": "e942c8b5-7c00-404f-8279-4ae4a1a92d7f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "data.bptt, len(data.valid_dl)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(70, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jJ-4BoSREGng",
        "colab_type": "text"
      },
      "source": [
        "Run the following code blocks to see how the data and its labels are organized. \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Klp2P6GVxFKg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "v = data.valid_ds.vocab"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UVGRuKobxWjt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "it = iter(data.valid_dl)\n",
        "x1,y1 = next(it)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iEzjtK_RxGLk",
        "colab_type": "code",
        "outputId": "2d8d63ff-531f-4cf6-f54e-36cb28f1540d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "v.textify(x1[0])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'xxbos eight thousand one , eight thousand two , eight thousand three , eight thousand four , eight thousand five , eight thousand six , eight thousand seven , eight thousand eight , eight thousand nine , eight thousand ten , eight thousand eleven , eight thousand twelve , eight thousand thirteen , eight thousand fourteen , eight thousand fifteen , eight thousand sixteen , eight thousand seventeen , eight'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s4THhJxCxJCq",
        "colab_type": "code",
        "outputId": "770702ad-e5be-4672-c011-511b4850d70a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "v.textify(y1[0])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'eight thousand one , eight thousand two , eight thousand three , eight thousand four , eight thousand five , eight thousand six , eight thousand seven , eight thousand eight , eight thousand nine , eight thousand ten , eight thousand eleven , eight thousand twelve , eight thousand thirteen , eight thousand fourteen , eight thousand fifteen , eight thousand sixteen , eight thousand seventeen , eight thousand'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "blzX2k3DEp0w",
        "colab_type": "text"
      },
      "source": [
        "`x1` is one batch from the validation dataset. Notice how the labels for that batch are in `y1`, and that `y1` is essentially the words in `x1` but shifted one to the right. That is because the correct answer for any given word is the word following it. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HG6kBJdmEFhy",
        "colab_type": "text"
      },
      "source": [
        "The fast.ai library does not yet include an RNN learner, but we can use PyTorch to create one. We create a class, called `Model`. Inside the model, we use the individual layers included in PyTorch. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GfwW74sTxKVp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "nv = len(v.itos)\n",
        "nh=64\n",
        "bs=64   #batch size\n",
        "class Model(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.i_h = nn.Embedding(nv,nh)\n",
        "        self.rnn = nn.RNN(nh,nh, batch_first=True)\n",
        "        self.h_o = nn.Linear(nh,nv)\n",
        "        self.bn = BatchNorm1dFlat(nh)\n",
        "        self.h = torch.zeros(1, bs, nh).cuda()\n",
        "        \n",
        "    def forward(self, x):\n",
        "        res,h = self.rnn(self.i_h(x), self.h)\n",
        "        self.h = h.detach()\n",
        "        return self.h_o(self.bn(res))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q2qfBOdyF9G5",
        "colab_type": "text"
      },
      "source": [
        "Now we can create a `learner` object called `learn` by passing through the data we want to use and the model structure. We include `accuracy` as one of the metrics we want to print out. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vUT9nqOpxOs2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "learn = Learner(data, Model(), metrics=accuracy)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5KCjx5ebGJNY",
        "colab_type": "text"
      },
      "source": [
        "We train our model for 30 epochs with a learning rate of 3e-3, which will change based off of the one cycle learning rate pattern. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Y7299ZIxP0B",
        "colab_type": "code",
        "outputId": "737cc3f4-cb36-4278-b435-fb126048f5e2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 947
        }
      },
      "source": [
        "learn.fit_one_cycle(30, 3e-3)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>3.780158</td>\n",
              "      <td>3.664972</td>\n",
              "      <td>0.030580</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>3.637743</td>\n",
              "      <td>3.427254</td>\n",
              "      <td>0.180208</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>3.400543</td>\n",
              "      <td>2.941130</td>\n",
              "      <td>0.424033</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>3.075920</td>\n",
              "      <td>2.417015</td>\n",
              "      <td>0.461384</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>2.733226</td>\n",
              "      <td>2.175397</td>\n",
              "      <td>0.467411</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>2.435847</td>\n",
              "      <td>2.212817</td>\n",
              "      <td>0.314583</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>2.203952</td>\n",
              "      <td>2.214181</td>\n",
              "      <td>0.315253</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>2.028279</td>\n",
              "      <td>2.183154</td>\n",
              "      <td>0.316443</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>1.895301</td>\n",
              "      <td>2.160851</td>\n",
              "      <td>0.317039</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>1.793393</td>\n",
              "      <td>2.171996</td>\n",
              "      <td>0.317188</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>1.711723</td>\n",
              "      <td>2.140703</td>\n",
              "      <td>0.317560</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11</td>\n",
              "      <td>1.638415</td>\n",
              "      <td>1.928257</td>\n",
              "      <td>0.367485</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12</td>\n",
              "      <td>1.569477</td>\n",
              "      <td>1.814434</td>\n",
              "      <td>0.452381</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>13</td>\n",
              "      <td>1.498587</td>\n",
              "      <td>1.791802</td>\n",
              "      <td>0.463616</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>14</td>\n",
              "      <td>1.425171</td>\n",
              "      <td>1.752424</td>\n",
              "      <td>0.497024</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>15</td>\n",
              "      <td>1.346916</td>\n",
              "      <td>1.664438</td>\n",
              "      <td>0.538839</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>16</td>\n",
              "      <td>1.271283</td>\n",
              "      <td>1.616270</td>\n",
              "      <td>0.552307</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>17</td>\n",
              "      <td>1.199939</td>\n",
              "      <td>1.589303</td>\n",
              "      <td>0.553348</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>18</td>\n",
              "      <td>1.134394</td>\n",
              "      <td>1.557485</td>\n",
              "      <td>0.562426</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>19</td>\n",
              "      <td>1.072971</td>\n",
              "      <td>1.543828</td>\n",
              "      <td>0.577604</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>20</td>\n",
              "      <td>1.016357</td>\n",
              "      <td>1.556118</td>\n",
              "      <td>0.564063</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>21</td>\n",
              "      <td>0.964814</td>\n",
              "      <td>1.562294</td>\n",
              "      <td>0.558036</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>22</td>\n",
              "      <td>0.918552</td>\n",
              "      <td>1.555794</td>\n",
              "      <td>0.577083</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>23</td>\n",
              "      <td>0.877810</td>\n",
              "      <td>1.550165</td>\n",
              "      <td>0.600149</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>24</td>\n",
              "      <td>0.842344</td>\n",
              "      <td>1.551520</td>\n",
              "      <td>0.595610</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>25</td>\n",
              "      <td>0.811792</td>\n",
              "      <td>1.553216</td>\n",
              "      <td>0.597842</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>26</td>\n",
              "      <td>0.786061</td>\n",
              "      <td>1.552047</td>\n",
              "      <td>0.604762</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>27</td>\n",
              "      <td>0.764838</td>\n",
              "      <td>1.560385</td>\n",
              "      <td>0.605952</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>28</td>\n",
              "      <td>0.747533</td>\n",
              "      <td>1.556667</td>\n",
              "      <td>0.609003</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>29</td>\n",
              "      <td>0.733817</td>\n",
              "      <td>1.557111</td>\n",
              "      <td>0.607961</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "drj0iFEw0z0d",
        "colab_type": "text"
      },
      "source": [
        "Using a simple RNN model, we were able to reach an accuracy of 60.8% for predicting words! By increasing the number of layers in our model, we can increase our accuracy even more. "
      ]
    }
  ]
}